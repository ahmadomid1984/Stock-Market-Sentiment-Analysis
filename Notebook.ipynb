{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc07ea8",
   "metadata": {},
   "source": [
    "## Sentiment analysis for stock market trends with LightningChart Python\n",
    "\n",
    "### 1. Introduction\n",
    "Stock market sentiment analysis is a powerful tool for predicting market movements by analyzing the emotions and opinions expressed in news articles, social media, and other textual data sources. Utilizing Python for this analysis provides a flexible and efficient approach to harnessing these sentiments to inform trading strategies. This article will explore how to perform stock market sentiment analysis using Python, particularly focusing on utilizing LightningChart for visualization.\n",
    "\n",
    "#### 1.1 What is Stock Market Sentiment Analysis?\n",
    "Stock market sentiment analysis involves evaluating public sentiment to predict stock price movements. This process typically uses natural language processing (NLP) and machine learning techniques to analyze text from various sources, such as news articles, social media posts, and financial reports. By quantifying the sentiment expressed, analysts can gauge the market's mood and make informed predictions about stock price trends.\n",
    "\n",
    "#### 1.2 Importance of Sentiment Analysis in Stock Market Prediction\n",
    "Sentiment analysis plays a crucial role in stock market prediction because emotions and opinions significantly influence investor behavior. Positive news can drive stock prices up, while negative sentiments can cause them to collapse. By analyzing these sentiments, traders and analysts can gain insights into potential market movements and adjust their strategies accordingly. This method complements traditional financial analysis, providing a more holistic view of the market.\n",
    "\n",
    "#### 1.3 How Sentiment Analysis Impacts Stock Market Trends\n",
    "The impact of sentiment analysis on stock market trends is profound. It helps identify the underlying mood of the market, which can be a leading indicator of price movements. For instance, a surge in positive sentiments on social media about a particular stock can signal an upcoming price increase. Conversely, negative news can foreshadow a decline. By integrating sentiment analysis into their strategies, traders can anticipate and react to market changes more effectively.\n",
    "\n",
    "### 2. LightningChart Python \n",
    "\n",
    "#### 2.1 Overview of LightningChart Python\n",
    "LightningChart is a high-performance data visualization library that provides a wide range of chart types and features, ideal for visualizing complex data sets like those used in stock market sentiment analysis. Its Python version allows developers to create interactive, high-performance visualizations with ease.\n",
    "\n",
    "#### 2.2 Features and Chart Types to be Used in the Project\n",
    "LightningChart Python offers a variety of chart types, each designed to handle specific types of data visualization needs. In this project, we use the following chart types to visualize stock price prediction data:\n",
    "\n",
    "- **XY Chart**: For visualizing data in two dimensions with series types such as Line Series, Point Line Series, and Area Series.\n",
    "- **Line Chart**: Used for visualizing changes in stock prices over time.\n",
    "- **Area Chart**: Fills the area beneath a line series, useful for emphasizing volume or cumulative values.\n",
    "- **Bar Chart**: Used for visualizing categorical data as bars, making it easy to compare different categories side by side.\n",
    "- **Grouped Bar Chart**: Similar to the bar chart, but groups bars together based on additional categories, facilitating comparison within groups.\n",
    "- **Pie Chart**: This kind of chart visualizes proportions and percentages between categories by dividing a circle into proportional segments, providing a clear view of category distribution.\n",
    "- **Box Plot**: This chart type is used for visualizing data groups through quartiles. It is used to visualize the distribution of data based on statistical measures like quartiles, median, and outliers, providing insights into the data spread and variability.\n",
    "- **Pyramid Chart**: This chart type Visualizes proportions and percentages between categories, by dividing a pyramid into proportional segments.\n",
    "- **Spider Chart**: Chart for visualizing data in a radial form as dissected by named axes.\n",
    "\n",
    "![LighteningChart](./images/charts.png)\n",
    "\n",
    "#### 2.3 Performance Characteristics\n",
    "LightningChart handling millions of data points with ease and maintaining smooth user interactions. One of the standout aspects of LightningChart Python is its performance. The library is optimized for handling large volumes of data with minimal latency, which is crucial for financial applications where data needs to be processed and visualized in real-time to inform trading decisions.\n",
    "\n",
    "### 3. Setting Up Python Environment\n",
    "\n",
    "#### 3.1 Installing Python and Necessary Libraries\n",
    "Install Python from the [official website](https://www.python.org/downloads/) and use pip to install necessary libraries including LightningChart Python from PyPI. To get the [documentation](https://lightningchart.com/python-charts/docs/) and the [license](https://lightningchart.com/python-charts/), please visit [LightningChart Website](https://lightningchart.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9dfbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install lightningcharts random numpy pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b248e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:14:44.396997Z",
     "iopub.status.busy": "2023-10-25T17:14:44.396577Z",
     "iopub.status.idle": "2023-10-25T17:14:47.573283Z",
     "shell.execute_reply": "2023-10-25T17:14:47.571758Z"
    },
    "papermill": {
     "duration": 3.191401,
     "end_time": "2023-10-25T17:14:47.578882",
     "exception": false,
     "start_time": "2023-10-25T17:14:44.387481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aomid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (0.2.40)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\python312\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\python312\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\python312\\lib\\site-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (5.2.2)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (4.2.1)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\python312\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (2.4.4)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\python312\\lib\\site-packages (from yfinance) (3.17.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\python312\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\python312\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\python312\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aomid\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests>=2.31->yfinance) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries and LighteningChart license \n",
    "import lightningchart as lc\n",
    "import random\n",
    "\n",
    "lc.set_license('my-license-key')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3f8a9",
   "metadata": {},
   "source": [
    "#### 3.2 Overview of Libraries Used\n",
    "- **LightningChart**: Advanced data visualization.\n",
    "- **NumPy**: Numerical computation.\n",
    "- **Pandas**: Data manipulation and analysis.\n",
    "- **NLTK**: Uses for natural language processing tasks.\n",
    "\n",
    "#### 3.3 Setting Up Your Development Environment\n",
    "Recommended IDEs include Jupyter Notebook, PyCharm, or Visual Studio Code.\n",
    "\n",
    "### 4. Loading and Processing Data\n",
    "\n",
    "#### 4.1 How to Load the Data Files\n",
    "To perform stock market sentiment analysis, you'll need historical stock price data and sentiment data from social media. For this example, we will use the stock data for Apple from yfinance and a Twitter dataset containing all tweets related to Apple company:\n",
    "\n",
    "#### Load and Merge Twitter Data:\n",
    "Use Pandas to load and merge CSV files containing tweets and company tweets related to Apple in 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c38d374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:14:47.596905Z",
     "iopub.status.busy": "2023-10-25T17:14:47.596339Z",
     "iopub.status.idle": "2023-10-25T17:15:25.109853Z",
     "shell.execute_reply": "2023-10-25T17:15:25.108639Z"
    },
    "papermill": {
     "duration": 37.526243,
     "end_time": "2023-10-25T17:15:25.113229",
     "exception": false,
     "start_time": "2023-10-25T17:14:47.586986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tweets\n",
    "tweets=pd.read_csv('./Tweet.csv')\n",
    "company_tweet=pd.read_csv('./Company_Tweet.csv')\n",
    "\n",
    "tweets=tweets.merge(company_tweet,how='left',on='tweet_id')\n",
    "# format dates\n",
    "tweets['date'] = pd.to_datetime(tweets['post_date'], unit='s').dt.date\n",
    "tweets.date=pd.to_datetime( tweets.date,errors='coerce')\n",
    "tweets['time'] = pd.to_datetime(tweets['post_date'], unit='s').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ab9cfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:15:25.147621Z",
     "iopub.status.busy": "2023-10-25T17:15:25.147200Z",
     "iopub.status.idle": "2023-10-25T17:15:25.169661Z",
     "shell.execute_reply": "2023-10-25T17:15:25.168458Z"
    },
    "papermill": {
     "duration": 0.034558,
     "end_time": "2023-10-25T17:15:25.172407",
     "exception": false,
     "start_time": "2023-10-25T17:15:25.137849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>1420070457</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>1420070496</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>1420070510</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>1420070807</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:06:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:10:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id           writer   post_date  \\\n",
       "0  550441509175443456  VisualStockRSRC  1420070457   \n",
       "1  550441672312512512      KeralaGuy77  1420070496   \n",
       "2  550441732014223360      DozenStocks  1420070510   \n",
       "3  550442977802207232     ShowDreamCar  1420070807   \n",
       "4  550443807834402816     i_Know_First  1420071005   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1  Insanity of today weirdo massive selling. $aap...            0   \n",
       "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "\n",
       "   retweet_num  like_num ticker_symbol       date      time  \n",
       "0            0         1          AAPL 2015-01-01  00:00:57  \n",
       "1            0         0          AAPL 2015-01-01  00:01:36  \n",
       "2            0         0          AMZN 2015-01-01  00:01:50  \n",
       "3            0         1          TSLA 2015-01-01  00:06:47  \n",
       "4            0         1          AAPL 2015-01-01  00:10:05  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62971975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique ticker symbols: 6\n",
      "Unique ticker symbols:\n",
      "['AAPL' 'AMZN' 'TSLA' 'MSFT' 'GOOG' 'GOOGL']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values in the 'ticker_symbol' column\n",
    "unique_ticker_symbols = tweets['ticker_symbol'].unique()\n",
    "\n",
    "# Print the number of unique values\n",
    "print(f\"Number of unique ticker symbols: {len(unique_ticker_symbols)}\")\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique ticker symbols:\")\n",
    "print(unique_ticker_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594af09",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Grouped Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c5617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:57919\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2622c1718b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:23:18] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Grouped Bar Chart\n",
    "# Assuming 'tweets' DataFrame is already prepared and loaded with tweet data\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "tweets['year'] = tweets['date'].dt.year\n",
    "\n",
    "# Get the unique ticker symbols\n",
    "unique_ticker_symbols = tweets['ticker_symbol'].unique()\n",
    "\n",
    "# Initialize lists to store years and tweet counts for each ticker\n",
    "years = sorted(tweets['year'].unique())\n",
    "data = []\n",
    "\n",
    "# Loop through each unique ticker symbol and get the tweet counts per year\n",
    "for ticker in unique_ticker_symbols:\n",
    "    ticker_tweets = tweets[tweets['ticker_symbol'] == ticker]\n",
    "    tweet_counts = ticker_tweets.groupby('year').size().reindex(years, fill_value=0)\n",
    "    data.append({'subCategory': ticker, 'values': tweet_counts.values.tolist()})\n",
    "\n",
    "# Prepare year labels as strings\n",
    "year_labels = [str(year) for year in years]\n",
    "\n",
    "# Initialize LightningChart\n",
    "chart = lc.BarChart(\n",
    "    vertical=True,\n",
    "    theme=lc.Themes.Dark,\n",
    "    title='Number of Tweets per Year for Each Company'\n",
    ")\n",
    "\n",
    "# Set data for the chart\n",
    "chart.set_data_grouped(\n",
    "    year_labels,\n",
    "    data\n",
    ")\n",
    "\n",
    "# Add a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)\n",
    "\n",
    "# Set sorting and display the chart\n",
    "chart.set_sorting('alphabetical')\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c596f39e",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Pyramid chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "788e6bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:57923\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2627d695a30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:23:19] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Pyramid Chart\n",
    "# Assuming 'tweets' DataFrame is already prepared and loaded with tweet data\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "tweets['year'] = tweets['date'].dt.year\n",
    "\n",
    "# Get the unique ticker symbols\n",
    "unique_ticker_symbols = tweets['ticker_symbol'].unique()\n",
    "\n",
    "# Initialize list to store total tweet counts for each ticker\n",
    "pyramid_data = []\n",
    "\n",
    "# Loop through each unique ticker symbol and get the total tweet counts\n",
    "for ticker in unique_ticker_symbols:\n",
    "    ticker_tweets = tweets[tweets['ticker_symbol'] == ticker]\n",
    "    total_tweet_count = ticker_tweets.shape[0]\n",
    "    pyramid_data.append({'name': ticker, 'value': total_tweet_count})\n",
    "\n",
    "\n",
    "chart = lc.PyramidChart(\n",
    "    slice_mode='height',\n",
    "    theme=lc.Themes.Dark,\n",
    "    title='Total Number of Tweets per Company'\n",
    ")\n",
    "\n",
    "# Add slices to the pyramid chart\n",
    "chart.add_slices(pyramid_data)\n",
    "\n",
    "# Add a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart).set_title('Companies')\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5860debe",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Spider chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eea0d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:57936\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26213b63170>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:23:21] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Spider Chart\n",
    "# Assuming 'tweets' DataFrame is already prepared and loaded with tweet data\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "tweets['year'] = tweets['date'].dt.year\n",
    "\n",
    "# Get the unique ticker symbols and years\n",
    "unique_ticker_symbols = tweets['ticker_symbol'].unique()\n",
    "years = sorted(tweets['year'].unique())\n",
    "\n",
    "chart = lc.SpiderChart(\n",
    "    theme=lc.Themes.Dark,\n",
    "    title='Total Number of Tweets per Company per Year'\n",
    ")\n",
    "\n",
    "chart.set_web_mode('circle')\n",
    "\n",
    "# Add series for each year to the spider chart\n",
    "for year in years:\n",
    "    spider_data = []\n",
    "    for ticker in unique_ticker_symbols:\n",
    "        ticker_tweets = tweets[(tweets['ticker_symbol'] == ticker) & (tweets['year'] == year)]\n",
    "        total_tweet_count = ticker_tweets.shape[0]\n",
    "        spider_data.append({'axis': ticker, 'value': total_tweet_count})\n",
    "    \n",
    "    series = chart.add_series()\n",
    "    series.add_points(spider_data)\n",
    "    series.set_name(f'Year {year}')\n",
    "\n",
    "# Add a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart).set_title('Years')\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a4a5f",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d953e069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:57943\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2622c1738f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:23:23] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Box Plot\n",
    "# Assuming 'tweets' DataFrame is already prepared and loaded with tweet data\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "tweets['year'] = tweets['date'].dt.year\n",
    "\n",
    "# Get the unique ticker symbols\n",
    "unique_ticker_symbols = tweets['ticker_symbol'].unique()\n",
    "\n",
    "# Initialize lists to store data for each ticker\n",
    "box_plot_data = []\n",
    "\n",
    "# Loop through each unique ticker symbol and calculate box plot statistics\n",
    "for idx, ticker in enumerate(unique_ticker_symbols):\n",
    "    ticker_tweets = tweets[tweets['ticker_symbol'] == ticker]\n",
    "    tweet_counts = ticker_tweets.groupby('year').size().values\n",
    "\n",
    "    if len(tweet_counts) == 0:\n",
    "        continue\n",
    "\n",
    "    median = np.median(tweet_counts).item()\n",
    "    lower_quartile = np.percentile(tweet_counts, 25).item()\n",
    "    upper_quartile = np.percentile(tweet_counts, 75).item()\n",
    "    lower_extreme = np.min(tweet_counts).item()\n",
    "    upper_extreme = np.max(tweet_counts).item()\n",
    "    \n",
    "    box_plot_data.append({\n",
    "        'start': idx + 0.6,  # Start position for the box on x-axis\n",
    "        'end': idx + 1.4,  # End position for the box on x-axis\n",
    "        'median': median,\n",
    "        'lowerQuartile': lower_quartile,\n",
    "        'upperQuartile': upper_quartile,\n",
    "        'lowerExtreme': lower_extreme,\n",
    "        'upperExtreme': upper_extreme,\n",
    "        'label': ticker\n",
    "    })\n",
    "\n",
    "chart = lc.ChartXY(\n",
    "    theme=lc.Themes.Dark,\n",
    "    title='Box Plot of Tweet Counts per Year for Each Company'\n",
    ")\n",
    "\n",
    "# Add box series to the chart\n",
    "series = chart.add_box_series()\n",
    "series.add_multiple(box_plot_data)\n",
    "\n",
    "# Set x-axis to display company names using custom ticks\n",
    "x_axis = chart.get_default_x_axis()\n",
    "x_axis.set_interval(start=0.5, end=len(unique_ticker_symbols) + 0.5)\n",
    "\n",
    "for idx, ticker in enumerate(unique_ticker_symbols):\n",
    "    custom_tick = x_axis.add_custom_tick()\n",
    "    custom_tick.set_value(idx + 1)\n",
    "\n",
    "# Add text boxes above each box plot to display the company name\n",
    "for data in box_plot_data:\n",
    "    text_box = chart.add_textbox()\n",
    "    text_box.set_text(data['label'])\n",
    "    text_box.set_position(\n",
    "        x=(data['start'] + data['end']) / 2,\n",
    "        y=data['upperExtreme'] + 5000  # Position above the upper extreme\n",
    "    )\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7a675",
   "metadata": {},
   "source": [
    "#### 4.2 Handling and preprocessing the data\n",
    "After using Pandas to read the Twitter data into DataFrames, you need to preprocess the text data using NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741e3af0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:15:25.190694Z",
     "iopub.status.busy": "2023-10-25T17:15:25.190206Z",
     "iopub.status.idle": "2023-10-25T17:15:25.220666Z",
     "shell.execute_reply": "2023-10-25T17:15:25.219515Z"
    },
    "papermill": {
     "duration": 0.042437,
     "end_time": "2023-10-25T17:15:25.223072",
     "exception": false,
     "start_time": "2023-10-25T17:15:25.180635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple misses earnings, analyst suggest downgrade , sell now \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.213, 'neu': 0.787, 'pos': 0.0, 'compound': -0.2263}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(tweets,ticker='AAPL',start='2018-01-01',end='2018-12-31'):\n",
    "    #sbuset\n",
    "    df=tweets.loc[((tweets.ticker_symbol==ticker)&(tweets.date>=start)&(tweets.date<=end))]\n",
    "    # applt the SentimentIntensityAnalyzer\n",
    "    df.loc[:,('score')]=df.loc[:,'body'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "    # create label\n",
    "    #bins= pd.interval_range(start=-1, freq=3, end=1)\n",
    "    df.loc[:,('label')]=pd.cut(np.array(df.loc[:,'score']),bins=[-1, -0.66, 0.32, 1],right=True ,labels=[\"bad\", \"neutral\", \"good\"])\n",
    "    \n",
    "    df=df.loc[:,[\"date\",\"score\",\"label\",\"tweet_id\",\"body\"]]\n",
    "    return df\n",
    "\n",
    "print('apple misses earnings, analyst suggest downgrade , sell now ')\n",
    "sia.polarity_scores('apple misses earnings, analyst suggest downgrade , sell now ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "955b2c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:15:25.258056Z",
     "iopub.status.busy": "2023-10-25T17:15:25.257385Z",
     "iopub.status.idle": "2023-10-25T17:15:25.268650Z",
     "shell.execute_reply": "2023-10-25T17:15:25.267465Z"
    },
    "papermill": {
     "duration": 0.023447,
     "end_time": "2023-10-25T17:15:25.271019",
     "exception": false,
     "start_time": "2023-10-25T17:15:25.247572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple misses earnings, analyst suggest downgrade , sell now \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.535, 'neu': 0.465, 'pos': 0.0, 'compound': -0.7845}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customizing Sentiment Analyzer with Financial Lexicon\n",
    "positive_words='high profit Growth Potential Opportunity Bullish Strong Valuable Success Promising Profitable Win Winner Outstanding Record Earnings Breakthrough buy bull long support undervalued underpriced cheap upward rising trend moon rocket hold breakout call beat support buying holding'\n",
    "negative_words='resistance squeeze cover seller Risk Loss Decline Bearish Weak Declining Uncertain Troubling Downturn Struggle Unstable Volatile Slump Disaster Plunge sell bear bubble bearish short overvalued overbought overpriced expensive downward falling sold sell low put miss'\n",
    "\n",
    "dictOfpos = { i : 4 for i in positive_words.split(\" \") }\n",
    "dictOfneg = { i : -4 for i in negative_words.split(\" \")  }\n",
    "Financial_Lexicon = {**dictOfpos, **dictOfneg}\n",
    "\n",
    "sia.lexicon.update(Financial_Lexicon)\n",
    "\n",
    "\n",
    "print('apple misses earnings, analyst suggest downgrade , sell now ')\n",
    "sia.polarity_scores('apple misses earnings, analyst suggest downgrade , sell now ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "155bde91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:15:25.306399Z",
     "iopub.status.busy": "2023-10-25T17:15:25.305727Z",
     "iopub.status.idle": "2023-10-25T17:16:53.736860Z",
     "shell.execute_reply": "2023-10-25T17:16:53.735084Z"
    },
    "papermill": {
     "duration": 88.449913,
     "end_time": "2023-10-25T17:16:53.745740",
     "exception": false,
     "start_time": "2023-10-25T17:15:25.295827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aomid\\AppData\\Local\\Temp\\ipykernel_23716\\3573031547.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:,('score')]=df.loc[:,'body'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
      "C:\\Users\\aomid\\AppData\\Local\\Temp\\ipykernel_23716\\3573031547.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:,('label')]=pd.cut(np.array(df.loc[:,'score']),bins=[-1, -0.66, 0.32, 1],right=True ,labels=[\"bad\", \"neutral\", \"good\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2516892</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>good</td>\n",
       "      <td>947619846124122113</td>\n",
       "      <td>How is $AAPL @Apple going to get me to buy a #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516898</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>neutral</td>\n",
       "      <td>947622772800450561</td>\n",
       "      <td>$IBM settled -0.4% at $153.42, making for a 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516900</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>947623169241821184</td>\n",
       "      <td>$AAPL 2018, with 3 new handsets and possibly a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516909</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>good</td>\n",
       "      <td>947626570226728960</td>\n",
       "      <td>Start investing @RobinhoodApp and get a stock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516910</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>good</td>\n",
       "      <td>947626976642248704</td>\n",
       "      <td>JOIN NOW! TALK STOCKS IN OUR GOAL ORIENTED CHA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   score    label            tweet_id  \\\n",
       "2516892 2018-01-01  0.8807     good  947619846124122113   \n",
       "2516898 2018-01-01 -0.3612  neutral  947622772800450561   \n",
       "2516900 2018-01-01  0.0000  neutral  947623169241821184   \n",
       "2516909 2018-01-01  0.8561     good  947626570226728960   \n",
       "2516910 2018-01-01  0.4981     good  947626976642248704   \n",
       "\n",
       "                                                      body  \n",
       "2516892  How is $AAPL @Apple going to get me to buy a #...  \n",
       "2516898  $IBM settled -0.4% at $153.42, making for a 20...  \n",
       "2516900  $AAPL 2018, with 3 new handsets and possibly a...  \n",
       "2516909  Start investing @RobinhoodApp and get a stock ...  \n",
       "2516910  JOIN NOW! TALK STOCKS IN OUR GOAL ORIENTED CHA...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting tweets\n",
    "start='2018-01-01'\n",
    "end='2018-12-31'\n",
    "ticker='AAPL'\n",
    "tw=get_sentiment(tweets,ticker,start,end)\n",
    "tw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc9515",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38da185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58089\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2622c172990>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:23:59] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Sample data preparation using Pie Chart\n",
    "# Ensure the 'date' column is in datetime format\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "tweets['year'] = tweets['date'].dt.year\n",
    "\n",
    "# Filter tweets for AAPL\n",
    "aapl_tweets = tweets[tweets['ticker_symbol'] == 'AAPL']\n",
    "\n",
    "# Group by year and count the number of tweets\n",
    "tweet_counts = aapl_tweets.groupby('year').size()\n",
    "\n",
    "# Prepare data for LightningChart PieChart\n",
    "years = tweet_counts.index.astype(str).tolist()\n",
    "tweet_counts_values = tweet_counts.values.tolist()\n",
    "data = [{'name': year, 'value': value} for year, value in zip(years, tweet_counts_values)]\n",
    "\n",
    "\n",
    "chart = lc.PieChart(\n",
    "    labels_inside_slices=False,\n",
    "    title='Number of Tweets per Year for AAPL',\n",
    "    theme=lc.Themes.Dark\n",
    ")\n",
    "\n",
    "# Add slices to the pie chart\n",
    "chart.add_slices(data)\n",
    "chart.set_inner_radius(50)\n",
    "\n",
    "# Add a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(chart)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b8eec",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c910f404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58090\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26225f42270>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:24:00] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Bar chart\n",
    "# # Assuming 'tweets' DataFrame is already prepared and loaded with tweet data\n",
    "tweets['date'] = pd.to_datetime(tweets['date'])\n",
    "tweets['year'] = tweets['date'].dt.year\n",
    "\n",
    "# Filter tweets for AAPL\n",
    "aapl_tweets = tweets[tweets['ticker_symbol'] == 'AAPL']\n",
    "\n",
    "# Group by year and count the number of tweets\n",
    "tweet_counts = aapl_tweets.groupby('year').size()\n",
    "\n",
    "# Prepare data for LightningChart\n",
    "years = tweet_counts.index.astype(str).tolist()\n",
    "tweet_counts_values = tweet_counts.values.tolist()\n",
    "\n",
    "# Initialize LightningChart\n",
    "chart = lc.BarChart(\n",
    "    vertical=True,\n",
    "    theme=lc.Themes.Dark,\n",
    "    title='Number of Tweets per Year for AAPL'\n",
    ")\n",
    "\n",
    "# Define colors for each bar\n",
    "colors = [\"#FF5733\", \"#33FF57\", \"#3357FF\", \"#F5A623\", \"#D0021B\"]\n",
    "\n",
    "# Prepare data with color information\n",
    "data = []\n",
    "for year, value, color in zip(years, tweet_counts_values, colors):\n",
    "    data.append({\n",
    "        'category': year,\n",
    "        'value': value,\n",
    "        'color': color\n",
    "    })\n",
    "\n",
    "# Set data with color information\n",
    "chart.set_data(data)\n",
    "\n",
    "# Open the chart\n",
    "chart.set_sorting('alphabetical')\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce3e93",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Area chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae12b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aomid\\AppData\\Local\\Temp\\ipykernel_23716\\617311545.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  sentiment_counts = tw.groupby(['date', 'label']).size().unstack(fill_value=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58092\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26225f43e00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:24:01] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Area chart\n",
    "# # Assuming 'tw' DataFrame is already prepared and loaded with tweet sentiment data\n",
    "tw['date'] = pd.to_datetime(tw['date'])\n",
    "sentiment_counts = tw.groupby(['date', 'label']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create a LightningChart XY chart\n",
    "chart = lc.ChartXY(theme=lc.Themes.Dark, title='AAPL Daily Sentiment Distribution by Date (2018)')\n",
    "chart.get_default_x_axis().dispose()\n",
    "\n",
    "# Set the base time to January 1, 2018\n",
    "time_origin = pd.Timestamp(\"2018-01-01\").timestamp() * 1000  # Convert to milliseconds\n",
    "x_axis = chart.add_x_axis(axis_type='linear-highPrecision')\n",
    "x_axis.set_tick_strategy('DateTime', time_origin=time_origin)\n",
    "x_axis.set_interval(start=time_origin, end=time_origin + 365 * 24 * 3600 * 1000)\n",
    "\n",
    "# Convert date to milliseconds since epoch (for high precision axis)\n",
    "sentiment_counts.index = (sentiment_counts.index - pd.Timestamp(\"2018-01-01\")) // pd.Timedelta('1ms')\n",
    "\n",
    "# Adding area series for each sentiment and attempting a simple legend addition\n",
    "legend = chart.add_legend()\n",
    "\n",
    "# Define colors for each sentiment\n",
    "colors = {\n",
    "    'good': lc.Color(\"orange\"),\n",
    "    'neutral': lc.Color(\"gray\"), \n",
    "    'bad': lc.Color(\"brown\")\n",
    "}\n",
    "\n",
    "for sentiment in ['good', 'neutral', 'bad']:\n",
    "    if sentiment in sentiment_counts.columns:\n",
    "        series = chart.add_area_series()\n",
    "        x_values = sentiment_counts.index.values\n",
    "        y_values = sentiment_counts[sentiment].values\n",
    "        series.add(x_values, y_values)\n",
    "        series.set_name(sentiment.capitalize())\n",
    "        series.set_fill_color(colors[sentiment])\n",
    "        legend.add(series)\n",
    "\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12f770a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:16:54.733835Z",
     "iopub.status.busy": "2023-10-25T17:16:54.733436Z",
     "iopub.status.idle": "2023-10-25T17:16:54.938743Z",
     "shell.execute_reply": "2023-10-25T17:16:54.937500Z"
    },
    "papermill": {
     "duration": 0.221132,
     "end_time": "2023-10-25T17:16:54.941507",
     "exception": false,
     "start_time": "2023-10-25T17:16:54.720375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Average Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.380360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>0.325566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.256721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.330698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.187864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Average Score\n",
       "0  2018-01-01       0.380360\n",
       "1  2018-01-02       0.325566\n",
       "2  2018-01-03       0.256721\n",
       "3  2018-01-04       0.330698\n",
       "4  2018-01-05       0.187864"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime objects\n",
    "tw['date'] = pd.to_datetime(tw['date'])\n",
    "\n",
    "# Group the data by date and calculate the average sentiment score for each day\n",
    "daily_sentiment = tw.groupby(tw['date'].dt.date)['score'].mean()\n",
    "\n",
    "daily_sentiment_df = pd.DataFrame({'Date': daily_sentiment.index, 'Average Score': daily_sentiment.values})\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "daily_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1aebbf",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Line chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21ad618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:16:54.988150Z",
     "iopub.status.busy": "2023-10-25T17:16:54.987774Z",
     "iopub.status.idle": "2023-10-25T17:16:55.570516Z",
     "shell.execute_reply": "2023-10-25T17:16:55.568839Z"
    },
    "papermill": {
     "duration": 0.599825,
     "end_time": "2023-10-25T17:16:55.574819",
     "exception": false,
     "start_time": "2023-10-25T17:16:54.974994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58094\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x262274d8440>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:24:03] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Line chart\n",
    "# Assuming 'tw' DataFrame is already prepared and loaded with tweet sentiment data\n",
    "tw['date'] = pd.to_datetime(tw['date'])\n",
    "\n",
    "# Group the data by date and calculate the average sentiment score for each day\n",
    "daily_sentiment = tw.groupby(tw['date'].dt.date)['score'].mean()\n",
    "\n",
    "# Create a LightningChart XY chart\n",
    "chart = lc.ChartXY(\n",
    "    theme=lc.Themes.Dark,\n",
    "    title='AAPL Average Sentiment Score for Each Day for the year 2018'\n",
    ")\n",
    "chart.get_default_x_axis().dispose()\n",
    "\n",
    "# Set the base time to January 1, 2018\n",
    "time_origin = pd.Timestamp(\"2018-01-01\").timestamp() * 1000\n",
    "x_axis = chart.add_x_axis(axis_type='linear-highPrecision')\n",
    "x_axis.set_tick_strategy('DateTime', time_origin=time_origin)\n",
    "x_axis.set_title('Date')\n",
    "\n",
    "y_axis = chart.get_default_y_axis()\n",
    "y_axis.set_title('Average Sentiment Score')\n",
    "\n",
    "# Convert date to milliseconds since epoch (for high precision axis)\n",
    "x_values = ((pd.to_datetime(daily_sentiment.index) - pd.Timestamp(\"2018-01-01\")) / np.timedelta64(1, 'ms')).astype(np.int64)\n",
    "y_values = daily_sentiment.values\n",
    "\n",
    "# Add line series to the chart\n",
    "series = chart.add_line_series()\n",
    "series.add(x_values, y_values)\n",
    "\n",
    "# Customize series appearance\n",
    "series.set_name('Average Sentiment Score')\n",
    "series.set_line_thickness(2)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e6793",
   "metadata": {},
   "source": [
    "### Fetching Historical Data for Apple and Visualizing Data with LightningChart using Line chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480cc6e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:17:36.687726Z",
     "iopub.status.busy": "2023-10-25T17:17:36.687248Z",
     "iopub.status.idle": "2023-10-25T17:17:38.473161Z",
     "shell.execute_reply": "2023-10-25T17:17:38.471811Z"
    },
    "papermill": {
     "duration": 1.807361,
     "end_time": "2023-10-25T17:17:38.476428",
     "exception": false,
     "start_time": "2023-10-25T17:17:36.669067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58109\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2622ae7c500>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:24:04] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Line chart\n",
    "# Fetch historical data for Apple\n",
    "aapl = yf.Ticker(\"AAPL\")\n",
    "hist = aapl.history(period=\"max\")\n",
    "\n",
    "# Reset the index to make 'Date' a column\n",
    "hist.reset_index(inplace=True)\n",
    "hist['Date'] = pd.to_datetime(hist['Date'])\n",
    "\n",
    "# Create a LightningChart XY chart\n",
    "chart = lc.ChartXY(theme=lc.Themes.Dark, title=\"AAPL Open Price\")\n",
    "chart.get_default_x_axis().dispose()\n",
    "\n",
    "# Set the base time to the minimum date in the dataset\n",
    "time_origin = pd.Timestamp(hist['Date'].min()).timestamp() * 1000\n",
    "\n",
    "# Set up a high precision date-time axis\n",
    "x_axis = chart.add_x_axis(axis_type='linear-highPrecision')\n",
    "x_axis.set_tick_strategy('DateTime', time_origin=time_origin)\n",
    "x_axis.set_title('Date')\n",
    "\n",
    "y_axis = chart.get_default_y_axis()\n",
    "y_axis.set_title('Open Price ($)')\n",
    "\n",
    "# Convert date to milliseconds since epoch for high precision axis\n",
    "x_values = ((hist['Date'] - pd.Timestamp(hist['Date'].min())) / np.timedelta64(1, 'ms')).astype(np.int64).values\n",
    "y_values = hist['Open'].values\n",
    "\n",
    "# Add line series to the chart\n",
    "series = chart.add_line_series()\n",
    "series.add(x_values, y_values)\n",
    "\n",
    "# Customize series appearance\n",
    "series.set_name('AAPL Open Price')\n",
    "series.set_line_thickness(2)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75728e85",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart using Line chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea2c0b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:17:38.514077Z",
     "iopub.status.busy": "2023-10-25T17:17:38.513466Z",
     "iopub.status.idle": "2023-10-25T17:17:39.055093Z",
     "shell.execute_reply": "2023-10-25T17:17:39.053781Z"
    },
    "papermill": {
     "duration": 0.564151,
     "end_time": "2023-10-25T17:17:39.058364",
     "exception": false,
     "start_time": "2023-10-25T17:17:38.494213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58111\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2622ae7da30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:24:04] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Line chart\n",
    "# Define the stock symbol and date range\n",
    "stock_symbol = \"AAPL\"\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2018-12-31\"\n",
    "\n",
    "# Create a Ticker object for the stock\n",
    "stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "# Fetch historical data for the specified date range\n",
    "hist = stock.history(period=\"1d\", start=start_date, end=end_date)\n",
    "\n",
    "# Reset the index to make 'Date' a column and ensure 'Date' is in datetime format\n",
    "hist.reset_index(inplace=True)\n",
    "hist['Date'] = pd.to_datetime(hist['Date'])\n",
    "\n",
    "# Create a LightningChart XY chart\n",
    "chart = lc.ChartXY(theme=lc.Themes.Dark, title=f\"{stock_symbol} Close Price (Jan 1, 2018 - Dec 31, 2018)\")\n",
    "chart.get_default_x_axis().dispose()\n",
    "\n",
    "# Set the base time to the minimum date in the dataset\n",
    "time_origin = pd.Timestamp(hist['Date'].min()).timestamp() * 1000\n",
    "\n",
    "# Set up a high precision date-time axis\n",
    "x_axis = chart.add_x_axis(axis_type='linear-highPrecision')\n",
    "x_axis.set_tick_strategy('DateTime', time_origin=time_origin)\n",
    "x_axis.set_title('Date')\n",
    "\n",
    "y_axis = chart.get_default_y_axis()\n",
    "y_axis.set_title('Close Price ($)')\n",
    "\n",
    "# Convert date to milliseconds since epoch for high precision axis\n",
    "x_values = ((hist['Date'] - pd.Timestamp(hist['Date'].min())) / np.timedelta64(1, 'ms')).astype(np.int64).values\n",
    "y_values = hist['Close'].values\n",
    "\n",
    "# Add line series to the chart\n",
    "series = chart.add_line_series()\n",
    "series.add(x_values, y_values)\n",
    "\n",
    "# Customize series appearance\n",
    "series.set_name('AAPL Close Price')\n",
    "series.set_line_thickness(2)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f056d7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:17:39.098376Z",
     "iopub.status.busy": "2023-10-25T17:17:39.097005Z",
     "iopub.status.idle": "2023-10-25T17:17:39.127904Z",
     "shell.execute_reply": "2023-10-25T17:17:39.126176Z"
    },
    "papermill": {
     "duration": 0.054175,
     "end_time": "2023-10-25T17:17:39.131052",
     "exception": false,
     "start_time": "2023-10-25T17:17:39.076877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Close  Dividends       High        Low       Open  Stock Splits       Volume\n",
      "2018-01-01 00:00:00-05:00   0.000000        0.0   0.000000   0.000000   0.000000           0.0          0.0\n",
      "2018-01-02 00:00:00-05:00  40.615879        0.0  40.625312  39.908532  40.120738           0.0  102223600.0\n",
      "2018-01-03 00:00:00-05:00  40.608810        0.0  41.155827  40.545152  40.679546           0.0  118071600.0\n",
      "2018-01-04 00:00:00-05:00  40.797440        0.0  40.901184  40.573447  40.681905           0.0   89738400.0\n",
      "2018-01-05 00:00:00-05:00  41.261936        0.0  41.349175  40.802161  40.894116           0.0   94640000.0\n"
     ]
    }
   ],
   "source": [
    "# Define the stock symbol and date range\n",
    "stock_symbol = \"AAPL\"\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2018-12-31'\n",
    "\n",
    "# Create a Ticker object for the stock\n",
    "stock = yf.Ticker(stock_symbol)\n",
    "\n",
    "# Fetch historical data for the specified date range\n",
    "hist = stock.history(period=\"1d\", start=start_date, end=end_date)\n",
    "\n",
    "# Make sure 'hist' has a datetime index\n",
    "hist.index = pd.to_datetime(hist.index)\n",
    "\n",
    "# Create a date range covering the full date range (including weekends and holidays)\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Create a new DataFrame with the full date range\n",
    "full_hist = pd.DataFrame(index=date_range)\n",
    "\n",
    "# Localize the new DataFrame index if necessary\n",
    "if hist.index.tz is not None:\n",
    "    full_hist.index = full_hist.index.tz_localize(hist.index.tzinfo)\n",
    "\n",
    "# Merge or combine the new DataFrame with the existing 'hist' DataFrame\n",
    "full_hist = full_hist.combine_first(hist)\n",
    "\n",
    "# Fill NaN values if necessary\n",
    "full_hist = full_hist.fillna(0)\n",
    "\n",
    "# Setup display options to show all data in one row\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.width', 1000) \n",
    "\n",
    "# Print the updated DataFrame 'full_hist'\n",
    "print(full_hist.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665fb64",
   "metadata": {},
   "source": [
    "### Visualizing Data with LightningChart and making comparison between Apple Close Price and Average Twitter Sentiment Score using Line chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "626b6a6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-25T17:17:39.211640Z",
     "iopub.status.busy": "2023-10-25T17:17:39.210626Z",
     "iopub.status.idle": "2023-10-25T17:17:40.593495Z",
     "shell.execute_reply": "2023-10-25T17:17:40.592036Z"
    },
    "papermill": {
     "duration": 1.406745,
     "end_time": "2023-10-25T17:17:40.597119",
     "exception": false,
     "start_time": "2023-10-25T17:17:39.190374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:58112\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2622ae7df70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/Jun/2024 10:24:06] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Make comparison between Apple Close Price and Average Twitter Sentiment Score using line chart\n",
    "chart = lc.ChartXY(theme=lc.Themes.Dark, title='Apple Close Price and Average Twitter Sentiment Score')\n",
    "\n",
    "# Configure the default X-axis for date handling\n",
    "x_axis = chart.get_default_x_axis()\n",
    "x_axis.set_tick_strategy('DateTime')\n",
    "x_axis.set_interval(start=pd.Timestamp(start_date).timestamp() * 1000, end=pd.Timestamp(end_date).timestamp() * 1000)\n",
    "\n",
    "# Create a Y-axis for the stock prices\n",
    "y_axis1 = chart.get_default_y_axis()\n",
    "y_axis1.set_title('Stock Price ($)')\n",
    "\n",
    "# Add a secondary Y-axis for the sentiment scores\n",
    "y_axis2 = chart.add_y_axis(opposite=True)\n",
    "y_axis2.set_title('Sentiment Score')\n",
    "\n",
    "# Convert dates to milliseconds since Unix epoch\n",
    "dates = pd.to_datetime(full_hist.index).astype(np.int64) // 10**6\n",
    "\n",
    "# Add series for stock prices\n",
    "stock_prices = full_hist['Close'].fillna(0)\n",
    "stock_series = chart.add_line_series(y_axis=y_axis1)\n",
    "stock_series.set_line_thickness(2)  # Thick lines to simulate bars\n",
    "stock_series.add(dates, stock_prices)\n",
    "stock_series.set_name(\"Stock Price\")\n",
    "stock_series.set_line_color(lc.Color(\"gray\"))\n",
    "\n",
    "# Add series for sentiment scores\n",
    "sentiment_scores = daily_sentiment_df['Average Score'].fillna(0)\n",
    "sentiment_series = chart.add_line_series(y_axis=y_axis2)\n",
    "sentiment_series.add(dates, sentiment_scores)\n",
    "sentiment_series.set_name(\"Sentiment Score\")\n",
    "sentiment_series.set_line_color(lc.Color(\"orange\"))\n",
    "\n",
    "# Add a legend to the chart\n",
    "legend = chart.add_legend()\n",
    "legend.add(stock_series)\n",
    "legend.add(sentiment_series)\n",
    "\n",
    "# Open the chart\n",
    "chart.open()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b585ff",
   "metadata": {},
   "source": [
    "## Validation of the Study\n",
    "For the validation of the study, correlation coefficients and Granger causality tests were used.\n",
    "\n",
    "### Correlation Observation:\n",
    "\n",
    "- There appear to be some correlations between the sentiment score and stock price movements. For example, certain peaks in sentiment scores coincide with peaks in stock prices and vice versa.\n",
    "- In the initial months (January to March), there seems to be a relatively high correlation where spikes in sentiment scores correspond to increases in stock prices.\n",
    "\n",
    "The chart suggests a potential relationship between Twitter sentiment and stock price movements. While not all movements correlate perfectly, there are instances where high sentiment scores align with stock price increases. This indicates that monitoring social media sentiment could be a valuable tool for predicting stock price movements.\n",
    "\n",
    "#### For a more rigorous analysis and to show how these observasions are correlated or not, statistical methods such as correlation coefficients and Granger causality tests could be applied to quantify the relationship between sentiment scores and stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf1b35e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in daily_sentiment_df before renaming:\n",
      "Index(['Date', 'Average Score'], dtype='object')\n",
      "Head of full_hist:\n",
      "                Close  Dividends       High        Low       Open  Stock Splits       Volume\n",
      "2018-01-01   0.000000        0.0   0.000000   0.000000   0.000000           0.0          0.0\n",
      "2018-01-02  40.615879        0.0  40.625312  39.908532  40.120738           0.0  102223600.0\n",
      "2018-01-03  40.608810        0.0  41.155827  40.545152  40.679546           0.0  118071600.0\n",
      "2018-01-04  40.797440        0.0  40.901184  40.573447  40.681905           0.0   89738400.0\n",
      "2018-01-05  41.261936        0.0  41.349175  40.802161  40.894116           0.0   94640000.0\n",
      "Tail of full_hist:\n",
      "                Close  Dividends       High        Low       Open  Stock Splits       Volume\n",
      "2018-12-27  37.370178        0.0  37.518561  35.915102  37.295989           0.0  212468400.0\n",
      "2018-12-28  37.389320        0.0  37.937370  36.987261  37.693261           0.0  169165600.0\n",
      "2018-12-29   0.000000        0.0   0.000000   0.000000   0.000000           0.0          0.0\n",
      "2018-12-30   0.000000        0.0   0.000000   0.000000   0.000000           0.0          0.0\n",
      "2018-12-31   0.000000        0.0   0.000000   0.000000   0.000000           0.0          0.0\n",
      "Head of daily_sentiment_df:\n",
      "            Average Score\n",
      "Date                     \n",
      "2018-01-01       0.380360\n",
      "2018-01-02       0.325566\n",
      "2018-01-03       0.256721\n",
      "2018-01-04       0.330698\n",
      "2018-01-05       0.187864\n",
      "Tail of daily_sentiment_df:\n",
      "            Average Score\n",
      "Date                     \n",
      "2018-12-27       0.216067\n",
      "2018-12-28       0.223373\n",
      "2018-12-29       0.288359\n",
      "2018-12-30       0.356132\n",
      "2018-12-31       0.253560\n",
      "Number of overlapping data points: 365\n",
      "Head of merged_df:\n",
      "                Close  Average Score\n",
      "2018-01-01   0.000000       0.380360\n",
      "2018-01-02  40.615879       0.325566\n",
      "2018-01-03  40.608810       0.256721\n",
      "2018-01-04  40.797440       0.330698\n",
      "2018-01-05  41.261936       0.187864\n",
      "Tail of merged_df:\n",
      "                Close  Average Score\n",
      "2018-12-27  37.370178       0.216067\n",
      "2018-12-28  37.389320       0.223373\n",
      "2018-12-29   0.000000       0.288359\n",
      "2018-12-30   0.000000       0.356132\n",
      "2018-12-31   0.000000       0.253560\n",
      "Pearson correlation coefficient: -0.530767909708746\n",
      "P-value: 6.482098099400659e-28\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=7.7905  , p=0.0055  , df_denom=361, df_num=1\n",
      "ssr based chi2 test:   chi2=7.8552  , p=0.0051  , df=1\n",
      "likelihood ratio test: chi2=7.7717  , p=0.0053  , df=1\n",
      "parameter F test:         F=7.7905  , p=0.0055  , df_denom=361, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=30.3268 , p=0.0000  , df_denom=358, df_num=2\n",
      "ssr based chi2 test:   chi2=61.5007 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=56.8134 , p=0.0000  , df=2\n",
      "parameter F test:         F=30.3268 , p=0.0000  , df_denom=358, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=17.9410 , p=0.0000  , df_denom=355, df_num=3\n",
      "ssr based chi2 test:   chi2=54.8843 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=51.1016 , p=0.0000  , df=3\n",
      "parameter F test:         F=17.9410 , p=0.0000  , df_denom=355, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=25.6827 , p=0.0000  , df_denom=352, df_num=4\n",
      "ssr based chi2 test:   chi2=105.3574, p=0.0000  , df=4\n",
      "likelihood ratio test: chi2=92.4428 , p=0.0000  , df=4\n",
      "parameter F test:         F=25.6827 , p=0.0000  , df_denom=352, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=24.3062 , p=0.0000  , df_denom=349, df_num=5\n",
      "ssr based chi2 test:   chi2=125.3615, p=0.0000  , df=5\n",
      "likelihood ratio test: chi2=107.5643, p=0.0000  , df=5\n",
      "parameter F test:         F=24.3062 , p=0.0000  , df_denom=349, df_num=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\statsmodels\\tsa\\stattools.py:1545: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Ensure the Date column in daily_sentiment_df is in datetime format and set as index\n",
    "print(\"Columns in daily_sentiment_df before renaming:\")\n",
    "print(daily_sentiment_df.columns)\n",
    "\n",
    "# Check if 'Date' is in columns, otherwise print the columns available\n",
    "if 'Date' not in daily_sentiment_df.columns:\n",
    "    print(\"Column 'Date' not found. Available columns:\")\n",
    "    print(daily_sentiment_df.columns)\n",
    "else:\n",
    "    daily_sentiment_df['Date'] = pd.to_datetime(daily_sentiment_df['Date']).dt.tz_localize(None)\n",
    "    daily_sentiment_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Ensure the index of full_hist is in datetime format without timezone information and remove the time component\n",
    "full_hist.index = pd.to_datetime(full_hist.index).normalize().tz_localize(None)\n",
    "\n",
    "# Check the data\n",
    "print(\"Head of full_hist:\")\n",
    "print(full_hist.head())\n",
    "print(\"Tail of full_hist:\")\n",
    "print(full_hist.tail())\n",
    "\n",
    "print(\"Head of daily_sentiment_df:\")\n",
    "print(daily_sentiment_df.head())\n",
    "print(\"Tail of daily_sentiment_df:\")\n",
    "print(daily_sentiment_df.tail())\n",
    "\n",
    "# Merge the data on the date index\n",
    "merged_df = pd.merge(full_hist[['Close']], daily_sentiment_df[['Average Score']], left_index=True, right_index=True, how='inner')\n",
    "print(f\"Number of overlapping data points: {len(merged_df)}\")\n",
    "\n",
    "# Check the merged data\n",
    "print(\"Head of merged_df:\")\n",
    "print(merged_df.head())\n",
    "print(\"Tail of merged_df:\")\n",
    "print(merged_df.tail())\n",
    "\n",
    "# Correlation Analysis\n",
    "if len(merged_df) >= 2:\n",
    "    correlation_coefficient, p_value = pearsonr(merged_df['Close'], merged_df['Average Score'])\n",
    "    print(f\"Pearson correlation coefficient: {correlation_coefficient}\")\n",
    "    print(f\"P-value: {p_value}\")\n",
    "else:\n",
    "    print(\"Not enough data points for correlation analysis.\")\n",
    "\n",
    "# Granger Causality Test\n",
    "if len(merged_df) > 15:  # Assuming max_lag is 5, we need at least 15 data points\n",
    "    data = merged_df[['Average Score', 'Close']].dropna()\n",
    "    max_lag = 5\n",
    "    granger_result = grangercausalitytests(data, max_lag, verbose=True)\n",
    "else:\n",
    "    print(\"Not enough data points for Granger causality test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6132d39",
   "metadata": {},
   "source": [
    "### A. Pearson Correlation Analysis:\n",
    "* Pearson correlation coefficient: -0.5308\n",
    "* P-value: 6.4821e-28\n",
    "\n",
    "The Pearson correlation coefficient of -0.5308 indicates a moderate negative correlation between Apple's stock price and the average Twitter sentiment score. The negative value suggests that as the sentiment score increases, the stock price tends to decrease, and vice versa. The p-value is extremely low (6.48e-28), indicating that this result is statistically significant.\n",
    "\n",
    "### B. Granger Causality Tests:\n",
    "The Granger causality test is used to determine if one time series can predict another. Here, we tested various lags (from 1 to 5) to see if the sentiment scores can predict the stock price. The results indicate significant causality at all tested lags, with p-values well below 0.05.\n",
    "\n",
    "The key results for each lag are:\n",
    "\n",
    "* Lag 1: F=7.7905, p=0.0055\n",
    "* Lag 2: F=30.3268, p=0.0000\n",
    "* Lag 3: F=17.9410, p=0.0000\n",
    "* Lag 4: F=25.6827, p=0.0000\n",
    "* Lag 5: F=24.3062, p=0.0000\n",
    "\n",
    "For all lags (1 to 5), the P-values are extremely low, indicating that the average Twitter sentiment score Granger-causes Apple's stock price. This means that past values of the sentiment score can be used to predict future values of the stock price. The strong statistical significance across multiple lags reinforces the robustness of this finding.\n",
    "\n",
    "#### Results interpretations:\n",
    "* The negative correlation suggests that higher sentiment scores are associated with lower stock prices, and vice versa.\n",
    "* The Granger causality test indicates a predictive relationship, where sentiment scores can be used to forecast future stock prices.\n",
    "\n",
    "The results suggest that there is a significant negative correlation between Apple's stock price and the average Twitter sentiment score. Additionally, the Granger causality test indicates that the sentiment score can be used to predict future stock prices, highlighting a predictive relationship between these two variables. This analysis can be valuable for traders and analysts looking to incorporate social media sentiment into their stock price prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc1879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99e40f11",
   "metadata": {},
   "source": [
    "### 5. Visualizing Data with LightningChart\n",
    "\n",
    "#### Some results' images:\n",
    "\n",
    "![Chart](./images/11.png)\n",
    "![Chart](./images/10.png)\n",
    "![Chart](./images/9.png)\n",
    "![Chart](./images/8.png)\n",
    "![Chart](./images/7.png)\n",
    "![Chart](./images/6.png)\n",
    "![Chart](./images/5.png)\n",
    "![Chart](./images/4.png)\n",
    "![Chart](./images/3.png)\n",
    "![Chart](./images/2.png)\n",
    "![Chart](./images/1.png)\n",
    "\n",
    "### 6. Conclusion\n",
    "\n",
    "#### 6.1 Recap of creating the application\n",
    "In this project, we covered the essentials of performing stock market sentiment analysis using Python and visualizing the results with LightningChart. We discussed setting up the Python environment, loading and preprocessing data, and creating insightful visualizations with LightningChart.\n",
    "\n",
    "#### 6.2 Why is it useful?\n",
    "Stock market sentiment analysis using Python provides traders and analysts with a deeper understanding of market trends driven by public sentiment. This approach complements traditional analysis methods, offering a more comprehensive market view.\n",
    "\n",
    "#### 6.3 Benefits of using LightningChart Python for visualizing data\n",
    "LightningChart Python stands out for its high performance and flexibility, making it an ideal choice for visualizing large and complex datasets in real-time. Its wide range of features and customization options enables users to create informative and visually appealing charts, enhancing the overall analysis process.\n",
    "By leveraging the power of sentiment analysis and advanced visualization tools like LightningChart, traders can gain valuable insights and make more informed decisions in the dynamic world of stock trading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 182.076618,
   "end_time": "2023-10-25T17:17:42.647791",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-25T17:14:40.571173",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
